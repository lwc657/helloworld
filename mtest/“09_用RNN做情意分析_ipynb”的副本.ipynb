{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“09. 用RNN做情意分析.ipynb”的副本",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s2WRfAFq_pO",
        "colab_type": "text"
      },
      "source": [
        "我們終於要介紹三大神經網路的最後一個, 也就是 RNN。RNN 有不少的變型, 例如 LSTM 和 GRU 等等, 不過我們都通稱叫 RNN。RNN 是一種「有記憶」的神經網路, 非常適合時間序列啦, 或是不定長度的輸入資料。\n",
        "\n",
        "我們來看看怎麼樣用 RNN 做電影評論的「情意分析」, 也就是知道一則評論究竟是「正評」還是「負評」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvoy-2LEq_pQ",
        "colab_type": "text"
      },
      "source": [
        "## 09-01 初始準備\n",
        "\n",
        "基本上和之前是一樣的, 我們就不再說明。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgY-AjiIq_pR",
        "colab_type": "code",
        "outputId": "f6f0feb2-9bcd-42da-e911-d5448a992848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%env KERAS_BACKEND=tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: KERAS_BACKEND=tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "a73ce944-1f06-4b48-91eb-da5ff43936f9"
        },
        "id": "sXd_Y_GHq_pW",
        "colab_type": "code",
        "outputId": "ed03e36a-4da9-4cfa-b106-29539f494c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install numpy==1.16.1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0SPB7Kwq_pY",
        "colab_type": "text"
      },
      "source": [
        "## 09-02 讀入 IMDB 電影數據庫\n",
        "\n",
        "今天我們要評入 IMDB 電影數據庫影評的部份。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t_oCEzOq_pZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "474fe403-aff1-43d7-ee51-f9bc578584eb"
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoSu8edcq_pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUpW8jQ9q_pe",
        "colab_type": "text"
      },
      "source": [
        "要注意這裡我們限制只選「最常用」1 萬字, 也就是超過這範圍的就當不存在。這是文字分析常會做的事。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW62s8PXq_pe",
        "colab_type": "code",
        "outputId": "1313ff53-bf72-4916-d811-b8b03f938f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('訓練總筆數:', len(x_train))\n",
        "print('測試總筆數:', len(x_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練總筆數: 25000\n",
            "測試總筆數: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s64QZrw6q_ph",
        "colab_type": "text"
      },
      "source": [
        "### 輸入資料部份\n",
        "\n",
        "我們來看一下輸入部份長什麼樣子?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZXHOgPRq_pi",
        "colab_type": "code",
        "outputId": "6d95f6c4-fd29-4e3d-b3cb-f92cc5f5ee2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2669
        }
      },
      "source": [
        "x_train[24999]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 17,\n",
              " 6,\n",
              " 194,\n",
              " 337,\n",
              " 7,\n",
              " 4,\n",
              " 204,\n",
              " 22,\n",
              " 45,\n",
              " 254,\n",
              " 8,\n",
              " 106,\n",
              " 14,\n",
              " 123,\n",
              " 4,\n",
              " 2,\n",
              " 270,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 732,\n",
              " 2098,\n",
              " 101,\n",
              " 405,\n",
              " 39,\n",
              " 14,\n",
              " 1034,\n",
              " 4,\n",
              " 1310,\n",
              " 9,\n",
              " 115,\n",
              " 50,\n",
              " 305,\n",
              " 12,\n",
              " 47,\n",
              " 4,\n",
              " 168,\n",
              " 5,\n",
              " 235,\n",
              " 7,\n",
              " 38,\n",
              " 111,\n",
              " 699,\n",
              " 102,\n",
              " 7,\n",
              " 4,\n",
              " 4039,\n",
              " 9245,\n",
              " 9,\n",
              " 24,\n",
              " 6,\n",
              " 78,\n",
              " 1099,\n",
              " 17,\n",
              " 2345,\n",
              " 2,\n",
              " 21,\n",
              " 27,\n",
              " 9685,\n",
              " 6139,\n",
              " 5,\n",
              " 2,\n",
              " 1603,\n",
              " 92,\n",
              " 1183,\n",
              " 4,\n",
              " 1310,\n",
              " 7,\n",
              " 4,\n",
              " 204,\n",
              " 42,\n",
              " 97,\n",
              " 90,\n",
              " 35,\n",
              " 221,\n",
              " 109,\n",
              " 29,\n",
              " 127,\n",
              " 27,\n",
              " 118,\n",
              " 8,\n",
              " 97,\n",
              " 12,\n",
              " 157,\n",
              " 21,\n",
              " 6789,\n",
              " 2,\n",
              " 9,\n",
              " 6,\n",
              " 66,\n",
              " 78,\n",
              " 1099,\n",
              " 4,\n",
              " 631,\n",
              " 1191,\n",
              " 5,\n",
              " 2642,\n",
              " 272,\n",
              " 191,\n",
              " 1070,\n",
              " 6,\n",
              " 7585,\n",
              " 8,\n",
              " 2197,\n",
              " 2,\n",
              " 2,\n",
              " 544,\n",
              " 5,\n",
              " 383,\n",
              " 1271,\n",
              " 848,\n",
              " 1468,\n",
              " 2,\n",
              " 497,\n",
              " 2,\n",
              " 8,\n",
              " 1597,\n",
              " 8778,\n",
              " 2,\n",
              " 21,\n",
              " 60,\n",
              " 27,\n",
              " 239,\n",
              " 9,\n",
              " 43,\n",
              " 8368,\n",
              " 209,\n",
              " 405,\n",
              " 10,\n",
              " 10,\n",
              " 12,\n",
              " 764,\n",
              " 40,\n",
              " 4,\n",
              " 248,\n",
              " 20,\n",
              " 12,\n",
              " 16,\n",
              " 5,\n",
              " 174,\n",
              " 1791,\n",
              " 72,\n",
              " 7,\n",
              " 51,\n",
              " 6,\n",
              " 1739,\n",
              " 22,\n",
              " 4,\n",
              " 204,\n",
              " 131,\n",
              " 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsJIhWRzq_pk",
        "colab_type": "text"
      },
      "source": [
        "注意這其實是一個 list 而不是 array, 原因是每筆資料 (每段影評) 長度自然是不一樣的! 我們檢查一下前 10 筆的長度就可以知道。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXnvMy8iq_pl",
        "colab_type": "code",
        "outputId": "4a130aaf-64f3-4df2-9318-af93a991f077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train[24999])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVMrbE2Hq_pp",
        "colab_type": "code",
        "outputId": "6f93920a-e029-4e18-aeb6-9b509adf9181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train[9982])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhK2vvnaq_pr",
        "colab_type": "code",
        "outputId": "f8b489c9-c160-422c-f2f8-d5916829b0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train[9487])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEHR6Dj3q_pu",
        "colab_type": "text"
      },
      "source": [
        "最後要說明的是, 在每筆輸入資料的數字都代表英文的一個單字。編號方式是在我們資料庫裡所有文字的排序: 也就是出現頻率越高, 代表的數字就越小。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK9k4W1bq_pv",
        "colab_type": "text"
      },
      "source": [
        "### 輸出資料部份\n",
        "\n",
        "輸出方面應該很容易想像, 我們來看看前 10 筆。結果自然就是 0 (負評) 或 1 (正評)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4W_co4jq_pv",
        "colab_type": "code",
        "outputId": "18c436eb-c843-4786-a086-02b01226063b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgGao5v-q_py",
        "colab_type": "code",
        "outputId": "872c87fb-4f42-4b57-8da4-ba26623e3c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4i_rLjq_p1",
        "colab_type": "text"
      },
      "source": [
        "### 送入神經網路的輸入處理\n",
        "\n",
        "雖然 RNN 是可以處理不同長度的輸入, 在寫程式時我們還是要\n",
        "\n",
        "* 設輸入文字長度的上限\n",
        "* 把每段文字都弄成一樣長, 太短的後面補上 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jxRpMYyq_p2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD6qyZdyq_p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=256)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QND5Kp18q_p8",
        "colab_type": "code",
        "outputId": "0f1f6125-2991-43b5-a948-8e72b8956d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape\n",
        "x_train[3333]\n",
        "x_train.min()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hz5Yia1q_p_",
        "colab_type": "text"
      },
      "source": [
        "至此我們可以來寫我們的第一個 RNN 了!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oEGUOdLq_qA",
        "colab_type": "text"
      },
      "source": [
        "## 09-03 打造你的 RNN\n",
        "\n",
        "這裡我們選用 LSTM, 基本上用哪種 RNN 寫法都是差不多的!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1tRDrOq_qB",
        "colab_type": "text"
      },
      "source": [
        "### 決定神經網路架構\n",
        "\n",
        "* 先將 10000 維的文字壓到 N 維\n",
        "* 然後用 K 個 LSTM 神經元做隱藏層\n",
        "* 最後一個 output, 直接用 sigmoid 送出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_0UQe1Eq_qC",
        "colab_type": "text"
      },
      "source": [
        "### 建構我們的神經網路\n",
        "\n",
        "文字我們用 1-hot 表示是很標準的方式, 不過要注意的是, 因為我們指定要 1 萬個字, 所以每個字是用 1 萬維的向量表示! 這一來很浪費記憶空間, 二來字和字間基本上是沒有關係的。我們可以用某種「合理」的方式, 把字壓到比較小的維度, 這些向量又代表某些意思 (比如說兩個字代表的向量角度小表相關程度大) 等等。\n",
        "\n",
        "這聽來很複雜的事叫 \"word embedding\", 而事實上 Keras 會幫我們做。我們只需告訴 Keras 原來最大的數字是多少 (10000), 還有我們打算壓到幾維 (N)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKNGoZ8Mq_qC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 200 # 文字要壓到 N 維\n",
        "K = 32 # LSTM 有 K 個神經元"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMrWP-CJq_qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyJAr1DKq_qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFwoEDPtq_qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5239b368-1c6f-4196-98df-1bc42ded2c83"
      },
      "source": [
        "model.add(Embedding(10000, N))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSPfSRpbq_qN",
        "colab_type": "text"
      },
      "source": [
        "LSTM 層, 我們做 K 個 LSTM Cells。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fYXHWUuq_qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(K))\n",
        "model.add(Dropout(0.5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Jn7YDaq_qQ",
        "colab_type": "text"
      },
      "source": [
        "單純透過 sigmoid 輸出。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iagQ4EoMq_qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdAUa44cq_qV",
        "colab_type": "text"
      },
      "source": [
        "### 組裝\n",
        "\n",
        "這次我們用 binary_crossentropy 做我們的 loss function, 另外用一個很潮的 Adam 學習法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MezzB_Ezq_qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qt_YheWq_qX",
        "colab_type": "code",
        "outputId": "fc518f83-6d96-44f4-a2f4-1a4c7c80cbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                29824     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,029,857\n",
            "Trainable params: 2,029,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4iTGEYcq_qa",
        "colab_type": "code",
        "outputId": "a413fcbf-a6c7-4965-ac57-78f1c81c6056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(4*7 + 4)*K"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBPDE0GAUOiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=5, patience=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjzNxxsiq_qd",
        "colab_type": "text"
      },
      "source": [
        "## 09-04 訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKHWP2Mkq_qd",
        "colab_type": "text"
      },
      "source": [
        "我們用的 embedding 中, 會被 batch_size 影響輸入。輸入的 shape 會是\n",
        "\n",
        "    (batch_size, 每筆上限)\n",
        "    \n",
        "也就是 (32,100) 輸出是 (32,100,128), 其中 128 是我們決定要壓成幾維的向量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwtBHNrvq_qe",
        "colab_type": "code",
        "outputId": "d56a2b47-e1d8-483c-fa58-b5a17617e365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "         batch_size=32,\n",
        "         epochs=100,\n",
        "         validation_data=(x_test,y_test),\n",
        "          callbacks=[es])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/100\n",
            "25000/25000 [==============================] - 197s 8ms/step - loss: 0.4328 - acc: 0.8055 - val_loss: 0.3148 - val_acc: 0.8705\n",
            "Epoch 2/100\n",
            "25000/25000 [==============================] - 194s 8ms/step - loss: 0.2613 - acc: 0.9014 - val_loss: 0.3436 - val_acc: 0.8733\n",
            "Epoch 3/100\n",
            "25000/25000 [==============================] - 194s 8ms/step - loss: 0.1992 - acc: 0.9270 - val_loss: 0.3309 - val_acc: 0.8740\n",
            "Epoch 4/100\n",
            "25000/25000 [==============================] - 193s 8ms/step - loss: 0.1574 - acc: 0.9444 - val_loss: 0.3479 - val_acc: 0.8743\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6cc512a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTabpLNzq_qh",
        "colab_type": "text"
      },
      "source": [
        "## 09-05 檢視結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd1Blzgqq_qj",
        "colab_type": "text"
      },
      "source": [
        "### 分數\n",
        "\n",
        "我們照例來看看測試資料的分數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8j5szwgq_qj",
        "colab_type": "code",
        "outputId": "b6abdbef-6916-49bc-cd6d-1802caa03da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 27s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l54g3qmoq_ql",
        "colab_type": "code",
        "outputId": "65529c1d-5f6a-494f-df1c-09880e77a245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'測試資料的 loss = {score[0]}')\n",
        "print(f'測試資正確率 = {score[1]}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試資料的 loss = 0.3479089678812027\n",
            "測試資正確率 = 0.87432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k3UKto2q_qq",
        "colab_type": "text"
      },
      "source": [
        "### 儲存結果\n",
        "\n",
        "這裡有 8 成我們可以正確分辨, 看來還不差, 照例我們把結果存檔。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syu5c-fRq_qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "open('imdb_model_arch.json',\n",
        "     'w').write(model_json)\n",
        "model.save_weights('imdb_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeUdFKSlyMI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}