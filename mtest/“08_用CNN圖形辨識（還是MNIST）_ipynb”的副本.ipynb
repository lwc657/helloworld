{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“08. 用CNN圖形辨識（還是MNIST）.ipynb”的副本",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfh_083pQOJS",
        "colab_type": "text"
      },
      "source": [
        "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tf9wYmYQOJT",
        "colab_type": "text"
      },
      "source": [
        "## 8-1 初始準備\n",
        "\n",
        "基本上和之前是一樣的, 我們就不再說明。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3OfeEqSQOJU",
        "colab_type": "code",
        "outputId": "ee5eb232-fc6e-4b92-e3da-d7e8551e44dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%env KERAS_BACKEND=tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: KERAS_BACKEND=tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFBLcKJlQOJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYbnvgidQOJa",
        "colab_type": "text"
      },
      "source": [
        "## 8-2 讀入 MNIST 數據庫\n",
        "\n",
        "### 由 Keras 讀入 MNIST\n",
        "\n",
        "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGecuEAyQOJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ2BU7STQOJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRH6AXwFQOJg",
        "colab_type": "text"
      },
      "source": [
        "### 輸入格式整理\n",
        "\n",
        "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
        "\n",
        "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geEPZaZwQOJh",
        "colab_type": "code",
        "outputId": "94c21a3e-7fbe-465a-ca33-d8804cfc1503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train[1234].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvsDQWQtQOJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN 要的是 (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ag499ZqQOJm",
        "colab_type": "text"
      },
      "source": [
        "確認一下..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUrOq5wPQOJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1LOz3wPQOJp",
        "colab_type": "text"
      },
      "source": [
        "原來 28x28 矩陣..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amIQe4pFQOJq",
        "colab_type": "code",
        "outputId": "764147a9-6313-4d76-f1d0-3c4aa57baf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train[1234].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srt_rxVjQOJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = x_train[1234]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZt9RGCSQOJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape(28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSjWm28EQOJz",
        "colab_type": "code",
        "outputId": "8986bbaa-84c1-45e2-80dc-082034cba3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.imshow(X,  cmap='Greys')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f17be105cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxDU/wAkyxd0e+uSGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMrfwMpQOJ3",
        "colab_type": "text"
      },
      "source": [
        "### 輸出格式整理\n",
        "\n",
        "和上次一樣, 我們用標準 1-hot 方式處理。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdIREJBuQOJ4",
        "colab_type": "code",
        "outputId": "13fe9c5f-0b45-45a5-c10f-3aa9350c6c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[1234]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f00seMwGQOJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgJmhUeHQOJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUp4tTdZQOJ_",
        "colab_type": "code",
        "outputId": "85f9212e-390b-45b6-d136-c1aef029c0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[1234]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puM1LmhXQOKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYJD4FYyQOKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvyRxn6CQOKG",
        "colab_type": "text"
      },
      "source": [
        "## 8-3 打造你的 CNN\n",
        "\n",
        "### 決定神經網路架構、讀入相關套件\n",
        "\n",
        "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
        "\n",
        "我們上課的時候, 同學建議要做 3 次的 convolution + max-pooling, filter 大小都是 $5\\times 5$。\n",
        "\n",
        "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
        "* filter 大小都是 <span style=\"color:red;\">5x5</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
        "\n",
        "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 <span style=\"color:red;\">4, 8, 16</span>。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
        "\n",
        "* 只有 <span style=\"color:red;\">1</span> 個隱藏層, 使用 <span style=\"color:red;\">9</span> 個神經元 (這也是同學建議)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtANHzPIQOKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn1oSyTnQOKJ",
        "colab_type": "text"
      },
      "source": [
        "### 建構我們的神經網路\n",
        "\n",
        "一開始一樣是打開個空白的神經網路。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prCA9NbYQOKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0ReRx6YQOKQ",
        "colab_type": "text"
      },
      "source": [
        "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfre-ARsQOKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(40, (5, 5), padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDnoJtOBQOKT",
        "colab_type": "text"
      },
      "source": [
        "Max-Pooling!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oz2-4gsQOKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPool2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj_ajI9TQOKW",
        "colab_type": "text"
      },
      "source": [
        "第二次 Convolution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lt3CwHaQOKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(8, (5, 5), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlY_rdQWQOKY",
        "colab_type": "text"
      },
      "source": [
        "再 Max-Pooling!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tmnfdI4QOKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPool2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnsXZwEFQOKb",
        "colab_type": "text"
      },
      "source": [
        "第三次 Convolution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qucSsZaQQOKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(16, (5, 5), padding='same'))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO9ZxOPWQOKe",
        "colab_type": "text"
      },
      "source": [
        "Max-Pooling 最終回。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWx-s5S7QOKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPool2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixk3OeBfQOKg",
        "colab_type": "text"
      },
      "source": [
        "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRIbNNgdQOKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(9))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGv74MFmQOKi",
        "colab_type": "text"
      },
      "source": [
        "輸出和上次一樣!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-vAsSjmQOKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gy14CYTQOKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MB4t8tcQOKn",
        "colab_type": "text"
      },
      "source": [
        "### 組裝\n",
        "\n",
        "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lRcaglQOKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.compile(loss=\"categorical_crossentropy\",\n",
        "#              optimizer=Adadelta(),\n",
        "#              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7us0d9qFQOKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4XVVYPXQOKt",
        "colab_type": "text"
      },
      "source": [
        "### 檢視我們的神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ32RpdIQOKu",
        "colab_type": "code",
        "outputId": "13470650-ed92-4c8b-8abd-ef0ce170e400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 40)        1040      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 28, 28, 40)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 14, 14, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 8)         8008      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 7, 16)          3216      \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 144)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 9)                 1305      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                100       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,669\n",
            "Trainable params: 13,669\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0LoKo2iQOKy",
        "colab_type": "text"
      },
      "source": [
        "## 8-4 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1yY_bmaQOKz",
        "colab_type": "code",
        "outputId": "604762fc-4b68-4380-cb69-e79a9aff0d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3501
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=100, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0139 - acc: 0.9064\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0061 - acc: 0.9601\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0045 - acc: 0.9708\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0036 - acc: 0.9762\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0030 - acc: 0.9806\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0027 - acc: 0.9827\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0024 - acc: 0.9848\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0022 - acc: 0.9859\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0020 - acc: 0.9875\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0018 - acc: 0.9886\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0016 - acc: 0.9896\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0016 - acc: 0.9900\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0014 - acc: 0.9912\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0013 - acc: 0.9920\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9922\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0012 - acc: 0.9923\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0011 - acc: 0.9928\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0010 - acc: 0.9935\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0011 - acc: 0.9934\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 9.4377e-04 - acc: 0.9943\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.0010 - acc: 0.9937\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 8.9143e-04 - acc: 0.9945\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 8.6830e-04 - acc: 0.9946\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 8.5171e-04 - acc: 0.9947\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 8.9969e-04 - acc: 0.9944\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 7.3172e-04 - acc: 0.9956\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 7.3017e-04 - acc: 0.9956\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 7.7961e-04 - acc: 0.9951\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 7.4325e-04 - acc: 0.9953\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 7.4409e-04 - acc: 0.9954\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 6.1281e-04 - acc: 0.9963\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 7.0223e-04 - acc: 0.9956\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.7277e-04 - acc: 0.9965\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 6.1398e-04 - acc: 0.9963\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 6.4895e-04 - acc: 0.9959\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 6.4258e-04 - acc: 0.9961\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 6.1475e-04 - acc: 0.9962\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 4.8827e-04 - acc: 0.9972\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 5.9972e-04 - acc: 0.9965\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.8320e-04 - acc: 0.9963\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.7990e-04 - acc: 0.9972\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.0411e-04 - acc: 0.9970\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.7823e-04 - acc: 0.9971\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 5.3693e-04 - acc: 0.9967\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.2536e-04 - acc: 0.9969\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.4742e-04 - acc: 0.9968\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.3933e-04 - acc: 0.9967\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 5.3086e-04 - acc: 0.9968\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.4828e-04 - acc: 0.9968\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.7487e-04 - acc: 0.9971\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 5.2951e-04 - acc: 0.9968\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.2785e-04 - acc: 0.9976\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 5.0606e-04 - acc: 0.9968\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.1058e-04 - acc: 0.9976\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.5445e-04 - acc: 0.9968\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.4534e-04 - acc: 0.9973\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.9402e-04 - acc: 0.9971\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.0794e-04 - acc: 0.9971\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.3010e-04 - acc: 0.9969\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.6009e-04 - acc: 0.9973\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 4.3821e-04 - acc: 0.9974\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 5.4421e-04 - acc: 0.9968\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 4.2868e-04 - acc: 0.9976\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 5.2471e-04 - acc: 0.9969\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.1638e-04 - acc: 0.9975\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.9704e-04 - acc: 0.9970\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.4173e-04 - acc: 0.9968\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.3739e-04 - acc: 0.9975\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.9287e-04 - acc: 0.9972\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 4.9111e-04 - acc: 0.9971\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 4.2957e-04 - acc: 0.9975\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 4.4298e-04 - acc: 0.9974\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.2265e-04 - acc: 0.9970\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.6552e-04 - acc: 0.9967\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.3833e-04 - acc: 0.9975\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 3.8534e-04 - acc: 0.9978\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.4913e-04 - acc: 0.9974\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.2125e-04 - acc: 0.9977\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.2622e-04 - acc: 0.9969\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.3369e-04 - acc: 0.9974\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 3.2983e-04 - acc: 0.9981\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 3.3753e-04 - acc: 0.9981\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.4562e-04 - acc: 0.9969\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 3.1771e-04 - acc: 0.9982\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.4816e-04 - acc: 0.9969\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 5.1194e-04 - acc: 0.9971\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 3.6706e-04 - acc: 0.9979\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 3.8309e-04 - acc: 0.9978\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 4.2190e-04 - acc: 0.9976\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 3.9434e-04 - acc: 0.9977\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 3.7080e-04 - acc: 0.9980\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.8791e-04 - acc: 0.9973\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.0386e-04 - acc: 0.9971\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.3252e-04 - acc: 0.9976\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.7827e-04 - acc: 0.9974\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.8055e-04 - acc: 0.9972\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 3.8384e-04 - acc: 0.9979\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 5.8577e-04 - acc: 0.9966\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 4.9758e-04 - acc: 0.9972\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 4.0117e-04 - acc: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f179bd56438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk-_mmRSQOK2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "blg4ldX-QOK3",
        "colab_type": "text"
      },
      "source": [
        "## 8-5 結果測試"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNJJS5TQQOK3",
        "colab_type": "text"
      },
      "source": [
        "### 分數\n",
        "\n",
        "我們來看測試資料 (我們的 CNN 沒看過的)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbKwi9xcQOK4",
        "colab_type": "code",
        "outputId": "7d60440e-60b3-4453-eb4d-e96ba08fb29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 84us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGCJ40ZSQOK8",
        "colab_type": "text"
      },
      "source": [
        "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zzTT8C9QOK8",
        "colab_type": "code",
        "outputId": "88c74fef-44c2-4dfa-94af-ca93f35fd1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'測試資料的 loss: {score[0]:.5f}')\n",
        "print(f'測試資料的正確率: {score[1]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試資料的 loss: 0.00180\n",
            "測試資料的正確率: 0.9901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KG4S6hmNQOK_",
        "colab_type": "text"
      },
      "source": [
        "### 儲存結果\n",
        "\n",
        "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB0F4YYVQOK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('myCNNmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "D0k9PcvoQOLB",
        "colab_type": "text"
      },
      "source": [
        "### 欣賞一下成果\n",
        "\n",
        "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGSfrwFiQOLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRBnW0omQOLG",
        "colab_type": "text"
      },
      "source": [
        "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 `load_model` 的函式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGbViU9GQOLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfZrGBxZQOLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('myCNNmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdsLZgE0QOLL",
        "colab_type": "text"
      },
      "source": [
        "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5iyphmTQOLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict_classes(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2OWKpcaQOLM",
        "colab_type": "text"
      },
      "source": [
        "看來真的可以直接用!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqUcwaWQQOLN",
        "colab_type": "code",
        "outputId": "824e2c80-0fcc-459e-ee06-9af73b0594a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "pick = np.random.randint(1,9999, 5)\n",
        "\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
        "    plt.title(predict[pick[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABpCAYAAAAnQqjlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ1d62YUQOLQ",
        "colab_type": "text"
      },
      "source": [
        "## 小結論\n",
        "\n",
        "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
      ]
    }
  ]
}